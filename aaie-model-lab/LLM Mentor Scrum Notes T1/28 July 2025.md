# LLM Team Scrum Meeting Takeaway  
**Date:** 28 July 2025  

---

## Key Discussion Points  

### 1. Project Pivot & Product Owner Feedback  
- Product owner feedback confirmed that current work on tokenization, fine-tuning, and solution architecture will be documented but **not used this trimester**.  
- Due to **limited resources** and **uncertainty with GCP access**, the team will shift focus to **Prompt Engineering** and **Few-Shot Learning**.  
- Priority now is a **lightweight, resource-efficient, end-to-end system**.  

### 2. Revised Use Case  
- In addition to **AI content detection** and **feedback generation**, the model will assess whether students **meaningfully altered** GenAI-generated content.  
- Requires:  
  - Input file  
  - Feedback generation  
  - Later inclusion of **prompt logs** and **transformation summaries**  
- This extended use case **may not be completed** this trimester.  

### 3. Implementation Strategy  
- Two APIs to be developed:  
  1. **Feedback generation**  
  2. **Content detection**  
- Approach:  
  - Wrap models with APIs using **prompt engineering** and **few-shot examples**  
  - Prefer **small, open-source models** (e.g., Tiny LLaMA, Qwen) for initial deployment to avoid GCP reliance  
  - Consider **CPU-only inference** or **limited GPU usage**  

### 4. Short-Term Plan  
- **Arnav** to create short-term execution plan and internal team division into:  
  1. Prompt engineering  
  2. API development  
  3. Model deployment  
  4. Evaluation  

### 5. GitHub Workflow and Peer Review Process  
- **Mohtashim** set up GitHub repositories and documentation folders.  
- All documents to be in **Markdown (.md)** format and uploaded.  
- **Review Process:**  
  - 2 peer reviews → 1 senior leader review → upstream (Nebula) review  
  - Research work may skip senior leader review with Nebula’s approval  

### 6. Individual Updates  
- **Arnav:** Tokenization strategy (BPE, SentencePiece, Unigram LM) — document ready for peer review.  
- **Ed:** Researched Qwen small parameter variants; built inference pipeline on Colab CPU.  
- **Qasim:** Analyzed 1.1B & 1.3B parameter models; explored batch size vs. compute trade-offs.  
- **Nam:** Explored NanoGPT models; suggested 114M variant for initial testing.  
- **Prem:** Evaluated metrics (BLEU, perplexity, etc.).  
- **Umar:** Designed 3 architecture/data flow diagrams; will upload PNGs to repo.  
- **Khushi:** Migrated planner board; set up documentation tooling (Astro + Netlify).  
- **Mohtashim:** Flagged GitHub private repo restrictions; suggested public repo or GitHub Education Team plan — to be raised at leadership meeting.  

---

## Next Steps  
- Team to organize around four **primary work streams**:  
  1. Prompt Engineering  
  2. API Development  
  3. Model Deployment  
  4. Evaluation Pipeline  
- Tasks to be broken down into individual planner board cards.  
- GitHub to remain **single source of truth** for code and documentation.  
- Weekly Scrum meetings: **Every Tuesday, 8–9 PM (30 minutes)** to track progress.  

---
